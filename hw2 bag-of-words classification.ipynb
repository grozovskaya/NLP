{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sara7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_distances, cosine_similarity\n",
    "\n",
    "import math\n",
    "from razdel import tokenize\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_ru = stopwords.words('russian')\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор (любой) с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### векторы с дефолтной токенизацией:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_vect = TfidfVectorizer(min_df=10, max_df=0.3)\n",
    "\n",
    "# train\n",
    "x_dv = default_vect.fit_transform(train.comment)\n",
    "y_dv = train.toxic.values\n",
    "\n",
    "# test\n",
    "x_test_dv = default_vect.transform(test.comment)\n",
    "y_test_dv = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sara7\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.1, class_weight='balanced')\n",
    "clf.fit(x_dv, y_dv)\n",
    "preds = clf.predict(x_test_dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.86      0.87       954\n",
      "         1.0       0.74      0.77      0.75       488\n",
      "\n",
      "    accuracy                           0.83      1442\n",
      "   macro avg       0.81      0.82      0.81      1442\n",
      "weighted avg       0.83      0.83      0.83      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_dv, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### кастомная токенизация  razdel.tokenize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def razdel_tokenizer(set_of_comments):\n",
    "    tokens = []\n",
    "    for item in set_of_comments:\n",
    "        new_tokens = [word.text for word in list(tokenize(item))]\n",
    "        tokens.append(new_tokens)\n",
    "    return(tokens)\n",
    "\n",
    "def razdel_tokenizer1(thing):\n",
    "    return(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_rt:  (12970, 3464)\n",
      "y_rt:  (12970,)\n",
      "x_test_rt:  (1442, 3464)\n",
      "y_test_rt:  (1442,)\n"
     ]
    }
   ],
   "source": [
    "razdel_vect = TfidfVectorizer(lowercase=False,\n",
    "                                    tokenizer=razdel_tokenizer1,\n",
    "                                    max_df=0.3,\n",
    "                                    min_df=10)\n",
    "# train\n",
    "train_rt = razdel_tokenizer(train.comment)\n",
    "x_rt = razdel_vect.fit_transform(train_rt)\n",
    "y_rt = train.toxic.values\n",
    "\n",
    "print('x_rt: ', x_rt.shape)\n",
    "print('y_rt: ', y_rt.shape)\n",
    "\n",
    "# test\n",
    "test_rt = razdel_tokenizer(test.comment)\n",
    "x_test_rt = razdel_vect.transform(test_rt)\n",
    "y_test_rt = test.toxic.values\n",
    "\n",
    "print('x_test_rt: ', x_test_rt.shape)\n",
    "print('y_test_rt: ', y_test_rt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.82      0.84       954\n",
      "         1.0       0.68      0.75      0.71       488\n",
      "\n",
      "    accuracy                           0.80      1442\n",
      "   macro avg       0.77      0.79      0.78      1442\n",
      "weighted avg       0.80      0.80      0.80      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.1, class_weight='balanced')\n",
    "clf.fit(x_rt, y_rt)\n",
    "preds = clf.predict(x_test_rt)\n",
    "print(classification_report(y_test_rt, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Каждый раз получается, что дефолтная векторизация немного лучше._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуйте таблицу с абсолютными частотностями в семинарской тетрадке в таблицу с tfidf значениями. (Таблица - https://i.ibb.co/r5Nc2HC/abs-bow.jpg) Формула tfidf есть в семинаре на картнике с пояснениями на английском. \n",
    "Считать нужно в питоне. Формат итоговой таблицы может быть любым, главное, чтобы был код и можно было воспроизвести вычисления. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabledata = [['я и ты',1,1,1,0,0,0],\n",
    "             ['ты и я',1,1,1,0,0,0],\n",
    "             ['я, я и только я',3,0,1,1,0,0],\n",
    "             ['только не я',1,0,0,1,1,0],\n",
    "             ['он',0,0,0,0,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>я</th>\n",
       "      <th>ты</th>\n",
       "      <th>и</th>\n",
       "      <th>только</th>\n",
       "      <th>не</th>\n",
       "      <th>он</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>я и ты</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ты и я</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>я, я и только я</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>только не я</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>он</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            phrase  я  ты  и  только  не  он\n",
       "0           я и ты  1   1  1       0   0   0\n",
       "1           ты и я  1   1  1       0   0   0\n",
       "2  я, я и только я  3   0  1       1   0   0\n",
       "3      только не я  1   0  0       1   1   0\n",
       "4               он  0   0  0       0   0   1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(tabledata, columns = ['phrase','я','ты','и','только','не','он'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сначала преобразуем значения в относительные\n",
    "\n",
    "def make_relational(row):\n",
    "    phrase_len = sum([item for item in row if type(item) != str])\n",
    "    new_values = [item/phrase_len for item in row if type(item) != str]\n",
    "    new_row = [row[0]]\n",
    "    new_row.extend(new_values)\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "relational_tabledata = [make_relational(row) for row in tabledata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>я</th>\n",
       "      <th>ты</th>\n",
       "      <th>и</th>\n",
       "      <th>только</th>\n",
       "      <th>не</th>\n",
       "      <th>он</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>я и ты</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ты и я</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>я, я и только я</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>только не я</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>он</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            phrase         я        ты         и    только        не   он\n",
       "0           я и ты  0.333333  0.333333  0.333333  0.000000  0.000000  0.0\n",
       "1           ты и я  0.333333  0.333333  0.333333  0.000000  0.000000  0.0\n",
       "2  я, я и только я  0.600000  0.000000  0.200000  0.200000  0.000000  0.0\n",
       "3      только не я  0.333333  0.000000  0.000000  0.333333  0.333333  0.0\n",
       "4               он  0.000000  0.000000  0.000000  0.000000  0.000000  1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_df = pd.DataFrame(relational_tabledata, columns = ['phrase','я','ты','и','только','не','он'])\n",
    "rel_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cчитаем значение df\n",
    "\n",
    "def df_count(word):\n",
    "    df = sum([1 for v in list(rel_df[word].values) if v > 0])\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tf_idf(data):\n",
    "    N = len(data) # общее кол-во документов в выборке (кол-во строк в rel_df)\n",
    "\n",
    "    words = ['я', 'ты', 'и', 'только', 'не', 'он']\n",
    "\n",
    "    tf_idf_tabledata = []\n",
    "\n",
    "    for row in data:\n",
    "        index = data.index(row)\n",
    "        tf_idf_row = [row[0]]\n",
    "\n",
    "        for word in words:\n",
    "            tf = row[words.index(word)+1] # частотность слова x в документе y (значения в rel_df)\n",
    "            df = df_count(word) # кол-во документов, где встречается x\n",
    "\n",
    "            tf_idf = tf * math.log(N/df) # Ф О Р М У Л А !\n",
    "\n",
    "            tf_idf_row.append(tf_idf)\n",
    "\n",
    "        tf_idf_tabledata.append(tf_idf_row)\n",
    "        \n",
    "    return tf_idf_tabledata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_tabledata = make_tf_idf(relational_tabledata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>я</th>\n",
       "      <th>ты</th>\n",
       "      <th>и</th>\n",
       "      <th>только</th>\n",
       "      <th>не</th>\n",
       "      <th>он</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>я и ты</td>\n",
       "      <td>0.074381</td>\n",
       "      <td>0.30543</td>\n",
       "      <td>0.170275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ты и я</td>\n",
       "      <td>0.074381</td>\n",
       "      <td>0.30543</td>\n",
       "      <td>0.170275</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>я, я и только я</td>\n",
       "      <td>0.133886</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.102165</td>\n",
       "      <td>0.183258</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>только не я</td>\n",
       "      <td>0.074381</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305430</td>\n",
       "      <td>0.536479</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>он</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.609438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            phrase         я       ты         и    только        не        он\n",
       "0           я и ты  0.074381  0.30543  0.170275  0.000000  0.000000  0.000000\n",
       "1           ты и я  0.074381  0.30543  0.170275  0.000000  0.000000  0.000000\n",
       "2  я, я и только я  0.133886  0.00000  0.102165  0.183258  0.000000  0.000000\n",
       "3      только не я  0.074381  0.00000  0.000000  0.305430  0.536479  0.000000\n",
       "4               он  0.000000  0.00000  0.000000  0.000000  0.000000  1.609438"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_df = pd.DataFrame(tf_idf_tabledata, columns = ['phrase','я','ты','и','только','не','он'])\n",
    "\n",
    "tf_idf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Требования к моделям:   \n",
    "а) один классификатор должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров (можно ставить разные параметры tfidfvectorizer и countvectorizer)  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра (по возможности)  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  \n",
    "\n",
    "*random_seed не считается за параметр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "# Tfidf Vectorizer\n",
    "\n",
    "Tfidf_Vect = TfidfVectorizer(decode_error='ignore',\n",
    "                             stop_words=stopwords_ru,\n",
    "                             min_df=10,\n",
    "                             ngram_range=(1,2),\n",
    "                             max_df=0.3)\n",
    "\n",
    "# train\n",
    "x_tfidf = Tfidf_Vect.fit_transform(train.comment)\n",
    "y_tfidf = train.toxic.values\n",
    "\n",
    "# test\n",
    "x_test_tfidf = Tfidf_Vect.transform(test.comment)\n",
    "y_test_tfidf = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.79      0.81       954\n",
      "         1.0       0.62      0.67      0.64       488\n",
      "\n",
      "    accuracy                           0.75      1442\n",
      "   macro avg       0.72      0.73      0.72      1442\n",
      "weighted avg       0.75      0.75      0.75      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DecisionTree Classifier\n",
    "\n",
    "dec_tree_clf = DecisionTreeClassifier(splitter='random', class_weight='balanced')\n",
    "dec_tree_clf.fit(x_tfidf, y_tfidf)\n",
    "preds = dec_tree_clf.predict(x_test_tfidf)\n",
    "\n",
    "print(classification_report(y_test_tfidf, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Говори адрес, петушара, будешь у меня на камеру говорить, что Кузьма - не свинья и на коленях прощения просить\\n',\n",
       "  1.0),\n",
       " ('потому что на лурке пишут что он пидор\\n', 1.0),\n",
       " ('На сигареты и минималка и максималка. Но законы то у нас дырявые и зачастую противоречивые, вот так и суд расценивает попытку продавать сигареты ниже максимальной их стоимости как попытку стимулирования продажи табачных изделий. Так что по факту сигареты продаются всегда по максимальной стоимости. Но это речь о сигаретах, а что с табаком? Я такой инфы не нашёл.\\n',\n",
       "  1.0),\n",
       " ('Всем здесь занимали. Мне профсоюз инвалидов умственного труда номерок в эту очередь выдавал!\\n',\n",
       "  1.0),\n",
       " ('Мне кажется, что не чувствуется натуральности. Что это именно вещь которую носят, а не одевают ради дубля. Все костюмы и элементы слишком полированные, слишком чистые и идеальные, складывается впечатление, что каждый кадр они надевают новый костюм, а старый тут же в чистку.\\n',\n",
       "  1.0),\n",
       " ('А нахуя мы тогда налоги платим, пусть сами бюджет пополняют.\\n', 1.0),\n",
       " ('У него явно вышел новый альбом...\\n', 1.0),\n",
       " ('блин в коменты не дает фотки добавлять\\n', 1.0),\n",
       " ('Не просто похоже, а это и есть она, где горит красный это магазин иркутский , а где фары в далеке это Энергетик.\\n',\n",
       "  1.0),\n",
       " ('Хиккан после тех событий удалял что-нибудь годное? Видел какие-то вебмки с кухни с философ-чан',\n",
       "  1.0)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree_probs = dec_tree_clf.predict_proba(x_test_tfidf)\n",
    "dec_tree_count_list = Counter()\n",
    "\n",
    "for i in range(len(test.comment)):\n",
    "    dec_tree_count_list[test.comment[i]] = float(dec_tree_probs[i][1])\n",
    "\n",
    "dec_tree_count_list.most_common(10)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Довольно подозрительно, что (почти) у всех 100% вер-ть токсичности.._\n",
    "\n",
    "_Кроме того, не со всеми оценками классификатора я согласна._\n",
    "\n",
    "_На всякий случай надо присмотреться к результатам:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       ...,\n",
       "       [0.21931054, 0.78068946],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_tree_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Почему-то на поверхности оказываются одинаковые повторяющиеся результаты..._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Вышел покурить на балкон, а тут Ын курит. Постояли, покурили.\\n',\n",
       "  0.7806894575400859),\n",
       " ('А в чем тут оскорбление?', 0.7806894575400859),\n",
       " ('Я так заплатил 2000 за обезболивание, но зуб так и не восстановил-стало плохо с сердцем(\\n',\n",
       "  0.7806894575400859),\n",
       " ('Не давал бы пушистому лизать кофе. Тельце маленькое, может инфаркт ебнуть.\\n',\n",
       "  0.7806894575400859),\n",
       " ('Н Е К У К О Л Д Ы И Р А З У\\n', 0.7806894575400859),\n",
       " ('Алсо, еще один твит про маразматика\\n', 0.7806894575400859),\n",
       " ('1. Жидовка подтачивает государство. Никогда такого не было, ага. 2. Нахуй фемкам косметика для патриархалок , когда им нужно что-то типа кондиционеров для волос на теле? 3. В чем хамство лаша? На месте этой конторы, глядючи на эту харю, я бы даже и отвечать не стал. 4. Сделала много для фемок, открытую инсту не догадалась зарегать - ЭТО ШИН!!! И кстати почему ее феминоподсписочницы не зафоловили ее в этой инсте, сучки токсичные?\\n',\n",
       "  0.6655358519660756),\n",
       " ('Приписываю в гандоны и текущую власть!', 0.6655358519660756),\n",
       " ('Латентная гомосексуалия у всей ваты.\\n', 0.6655358519660756),\n",
       " ('да, очень злобная презлобная на\\n', 0.6655358519660756),\n",
       " ('Мать дизайнер, родственник пластический хирург, а брательник моряк дальнего плаванья.\\n',\n",
       "  0.6655358519660756),\n",
       " ('Вы что всерьёз мои высказывания восприняли?\\n', 0.6655358519660756),\n",
       " ('хорош врать, ты террорист-торчёк-шизофреник пруф: а вот без костюма да чутка учёный, миллиардер, филантроп\\n',\n",
       "  0.6655358519660756),\n",
       " ('Кстати сейчас цех запускаем как раз с стх310 и стх510. Неплохие станки.\\n',\n",
       "  0.6655358519660756),\n",
       " ('Кстати, почему 1 8 доля, а не 1 4? Наследников же четверо?\\n',\n",
       "  0.6655358519660756),\n",
       " ('- Вовочка, не суй пальцы в розетку. - так они туда не влазят... - а ты гвоздики возьми, придурок!\\n',\n",
       "  0.6655358519660756),\n",
       " (', Уточнения фотография пост содержит художественную фотографию; Примеры: замок, леопард; Некорректное использование: бытовое фото;\\n',\n",
       "  0.6655358519660756),\n",
       " ('Учитель русского что-ли?)\\n', 0.6655358519660756),\n",
       " ('Это обезьяна из азиатского зоопарка, я угадал?)\\n', 0.6388277303927917),\n",
       " ('А капиталистическая , это людоедская.\\n', 0.6388277303927917),\n",
       " ('Такой упаковки не было никогда. Или это прикол был?\\n', 0.6388277303927917),\n",
       " ('У нас это лодочка называлось', 0.6388277303927917),\n",
       " ('Это россиянские ментяры так называются\\n', 0.6388277303927917),\n",
       " ('А цензура - это колоотрезающее кольцо\\n', 0.6388277303927917),\n",
       " ('Передай это собакам. dixi\\n', 0.6388277303927917),\n",
       " ('Разве что симметрией кристаллической решетки. Это как ломать графит в карандаше не поперек(что элементарно) а вдоль.\\n',\n",
       "  0.6388277303927917),\n",
       " ('Люди спасаются на деревьях Люди\\n', 0.498728911486018),\n",
       " ('Какие адские бояны залезают в горячее\\n', 0.39878037512704423),\n",
       " ('На 2 картинке комплект для беременных или это со мной что то не то\\n', 0.0),\n",
       " ('А я когда квартиру купил, каждый месяц теряю на квартплату. И машину когда купил, теряю на бензин, то, страховку.\\n',\n",
       "  0.0),\n",
       " ('На вкус и цвет фломастеры разные. Тут коллективный разум не работает, так что я воздержусь наверно.\\n',\n",
       "  0.0),\n",
       " ('Может 500 руб в месяц на еду и являются причиной депрессии?\\n', 0.0),\n",
       " ('У нас как раз такая же живет) Купил бы картину...) Не напишете как связаться, цену?\\n',\n",
       "  0.0),\n",
       " ('Там не всё так просто и банально, наши в долю хотят войти и получить свой процентик в компании, вот может такие торги были, сначала вброс и заявления потом переговоры.\\n',\n",
       "  0.0),\n",
       " ('Спасибо за рецепт! Это замечательно вкусно!\\n', 0.0),\n",
       " ('Есть вероятность, что при новом снимут санкции.\\n', 0.0),\n",
       " ('Спасибо.Будем знать на заметку\\n', 0.0),\n",
       " ('Можно про обсуждаемые батареи в цифрах? Ресурс (циклов заряда-разряда до потери ёмкости), стоимость в валюте?\\n',\n",
       "  0.0),\n",
       " ('Запор же это хохлоповозка. Почему она под москальскими флагами?\\n', 0.0),\n",
       " ('Да потому что в апелляции на жалобу забили болт и даже не читали её. В этом вся суть нашей системы. А управляющие компании совместно с ресурсоснабжающими организациями просто воруют наши деньги. С жильцов деньги собирают, а дальше никому не платят. Причём не платят явно по сговору с руководством ресурсоснабжающих организаций(откаты платят). Как наберется значительная сумма долгов(миллионов за 100), проводят реорганизацию своей компании путём присоединения к какой-нибудь помойке. И всё-профит. На месте старой УК создают новую. Руководство ресурсоснабжающих компаний с денежкой в кармане, долги со временем спишут. Вот такой бизнес.\\n',\n",
       "  0.0),\n",
       " ('А как потом это стекло с локи снимать? На сепаратор класть и проволокой елозить? Или в морозилку? Я тут обычное китайское стекло с клеем по контуру заколебался с самсунга снимать, вклеилось так, что думал основное стекло самса лопнет, еле оторвал.\\n',\n",
       "  0.0),\n",
       " ('Когда выйграл джекпот но посыпались не деньги а снег ..\\n', 0.0),\n",
       " ('Была на таком мосту в Цинхуандао. В тот день экран был почему-то выключен и следовательно непрозрачным. Как только мы прошли через него вдруг он включился и китайцы которые как раз на него ступили такой ор устроили аж все вокруг подпрыгнули и схватились за перила\\n',\n",
       "  0.0),\n",
       " ('У меня есть карта типа Универсальная, с кредитным лимитом. Если платишь вовремя, никаких процентов, очень удобно. Но очень маленькая, 1000 грн (можно увеличить лимит, но и этого хватает). В принципе, я могу платить этой картой в магазах, если налички нет или не хватает в тот момент, а до конца месяца просто закинуть нужную сумму.\\n',\n",
       "  0.0),\n",
       " ('Погрешности всё равно были, плюс у многих треков скорость плавала. Я всегда ориентировался на слух\\n',\n",
       "  0.0),\n",
       " ('Фильм-то стоит и 3 раза посмотреть, чтоб доперет )\\n', 0.0),\n",
       " ('Было бы очень интересно почитать про мото транспорт в Швеции.)\\n', 0.0),\n",
       " ('Директор магазина собственноручно проверял и все пояснял. Так что сомнения появлялись в виду мнительности и моего занудства в критерии выбора техники. Все таки деньги даются непросто.\\n',\n",
       "  0.0),\n",
       " ('Прям небольшое путешествие во времени\\n', 0.0),\n",
       " ('От неё и не собираются отказываться, видимо, я некорректно выразилась. Она видоизменена, просто для вышеназванных категорий детей осуществляется не инклюзивная, а коррекционная работа в отдельных классах и школах. В начале, как и у нас, всех пытались запихнуть исключительно в инклюзию, однако с годами это видоизменилось',\n",
       "  0.0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим на результаты из середины\n",
    "\n",
    "dec_tree_count_list.most_common()[500:550]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Обнаруживаем, что в середине всё же есть другие, не абсолютные значения (которые, кстати, тоже повторяются)._\n",
    "\n",
    "_Уже сейчас, безотносительно к результатам второго классификатора, можно сказать, что, несмотря на хорошие показатели метрик, этот классификатор работает странно, если не сказать некорректно..._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2\n",
    "# Count Vectorizer\n",
    "\n",
    "Count_Vect = CountVectorizer(decode_error='ignore',\n",
    "                                 stop_words=stopwords_ru,\n",
    "                                 min_df=10,\n",
    "                                 ngram_range=(1,2),\n",
    "                                 max_df=0.3)\n",
    "\n",
    "# train\n",
    "x_count = Count_Vect.fit_transform(train.comment)\n",
    "y_count = train.toxic.values\n",
    "\n",
    "# test\n",
    "x_test_count = Count_Vect.transform(test.comment)\n",
    "y_test_count = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      0.84      0.80       954\n",
      "         1.0       0.60      0.48      0.53       488\n",
      "\n",
      "    accuracy                           0.72      1442\n",
      "   macro avg       0.68      0.66      0.67      1442\n",
      "weighted avg       0.71      0.72      0.71      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNeighbors Classifier\n",
    "\n",
    "kn_clf = KNeighborsClassifier(n_neighbors=8, metric='cosine')\n",
    "kn_clf.fit(x_count, y_count)\n",
    "preds = kn_clf.predict(x_test_count)\n",
    "\n",
    "print(classification_report(y_test_count, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_По метрикам DecisionTree как будто немного лучше, сейчас посмотрим на оценку для конкретных текстов_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('потому что на лурке пишут что он пидор\\n', 1.0),\n",
       " ('где расчехляет кулаки, ты врешь 4пик Заебала пиздеть, русня', 1.0),\n",
       " ('Бля, заебал он уже, во всякой бочке затычка. Где его нестиранные штаны в дальнейшем увидим?\\n',\n",
       "  1.0),\n",
       " ('мы покурим шышки Оп -- малолетний дебил. Конопля пригодная для хозяства и конопля для курения -- разные. Хозяйственую нельзя курить каннабиноидов в ней нет.\\n',\n",
       "  1.0),\n",
       " ('Да ладно тебе. Чуть что сразу модератор\\n', 1.0),\n",
       " ('У него к-к-к-комбо: нигер, педераст и баба\\n', 1.0),\n",
       " ('Союз дети скрепляют, но твоя шлюха в них не может.\\n', 1.0),\n",
       " ('АХАХАХАХАХАХАХ Ты в очередной раз доказываешь насколько ты тупой долбоёб.\\n',\n",
       "  1.0),\n",
       " ('Такой себе Антихрист для русских\\n', 1.0),\n",
       " ('Что блять за конференция мамашек?\\n', 1.0)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_probs = kn_clf.predict_proba(x_test_count)\n",
    "kn_count_list = Counter()\n",
    "\n",
    "for i in range(len(test.comment)):\n",
    "    kn_count_list[test.comment[i]] = float(kn_probs[i][1])\n",
    "\n",
    "kn_count_list.most_common(10)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25 , 0.75 ],\n",
       "       [1.   , 0.   ],\n",
       "       [0.875, 0.125],\n",
       "       ...,\n",
       "       [0.375, 0.625],\n",
       "       [1.   , 0.   ],\n",
       "       [1.   , 0.   ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Этот классификатор, хоть и проигрывает по значениям метрик, показывает более адекватные результаты: я в большей степени согласна с его выборкой токсичных комментов, нежели с результатами предыдущего классфикатора._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Задание 4 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для классификаторов LogisticRegression и Random Forest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stopwords = ['очень'] # потому что позже оно вылезает в частотных и лучше его сразу убрать\n",
    "new_stopwords.extend(stopwords_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(ngram_range=(1, 3),\n",
    "                             min_df=5,\n",
    "                             max_df=0.2,\n",
    "                             stop_words=new_stopwords)\n",
    "\n",
    "# train\n",
    "x_train = vect.fit_transform(train.comment)\n",
    "y_train = train.toxic.values\n",
    "\n",
    "# test\n",
    "x_test = vect.transform(test.comment)\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7934"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist = [morph.parse(word)[0].normal_form for word in vect.get_feature_names()]\n",
    "len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.86      0.87       954\n",
      "         1.0       0.74      0.78      0.76       488\n",
      "\n",
      "    accuracy                           0.83      1442\n",
      "   macro avg       0.81      0.82      0.82      1442\n",
      "weighted avg       0.84      0.83      0.84      1442\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sara7\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "log_reg_clf = LogisticRegression(C=0.1, class_weight='balanced')\n",
    "log_reg_clf.fit(x_train, y_train)\n",
    "preds = log_reg_clf.predict(x_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coefficient of the features in the decision function.\n",
    "\n",
    "log_reg_coef = log_reg_clf.coef_\n",
    "log_reg_coef_counter_list = Counter()\n",
    "for i in range(len(wordlist)):\n",
    "    log_reg_coef_counter_list[wordlist[i]] = log_reg_coef[0][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('хохлов', 1.546664875990788),\n",
       " ('блять', 1.102446652268356),\n",
       " ('блядь', 1.0808134849701856),\n",
       " ('пиздец', 1.0174797919903233),\n",
       " ('сук', 1.0032950220542616)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg_coef_counter_list.most_common(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.68      1.00      0.81       954\n",
      "         1.0       0.97      0.06      0.12       488\n",
      "\n",
      "    accuracy                           0.68      1442\n",
      "   macro avg       0.82      0.53      0.46      1442\n",
      "weighted avg       0.77      0.68      0.57      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, max_depth=20, )\n",
    "rf_clf.fit(x_train, y_train)\n",
    "preds = rf_clf.predict(x_test)\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The impurity-based feature importances.\n",
    "\n",
    "rf_coef = rf_clf.feature_importances_\n",
    "rf_coef_counter_list = Counter()\n",
    "for i in range(len(wordlist)):\n",
    "    rf_coef_counter_list[wordlist[i]] = rf_coef[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('блядь', 0.021707386556318493),\n",
       " ('пиздец', 0.020068699935043517),\n",
       " ('хохлов', 0.017702619745936853),\n",
       " ('блять', 0.01677294246402691),\n",
       " ('сук', 0.01657295451677767)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_coef_counter_list.most_common(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
