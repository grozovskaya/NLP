{"cells":[{"cell_type":"markdown","id":"1dba7c0d","metadata":{"id":"1dba7c0d"},"source":["# Домашнее задание № 11. Машинный перевод"]},{"cell_type":"markdown","id":"Yj7aripVIsbG","metadata":{"id":"Yj7aripVIsbG"},"source":["## Задание 1 (6 баллов + 2 доп балла).\n","Нужно обучить трансформер на этом же или на другом корпусе (можно взять другую языковую пару с того же сайта) и оценивать его на всей тестовой выборке (а не на 10 примерах как сделал я). \n","\n","Чтобы получить 2 доп балла вам нужно будет придумать как оптимизировать функцию translate. Подсказка: модель может предсказывать батчами.\n"]},{"cell_type":"code","source":["!apt-get install unzip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SgQGMZjYJrxV","executionInfo":{"status":"ok","timestamp":1681971534436,"user_tz":-180,"elapsed":1883,"user":{"displayName":"Gloria Rozovskaya","userId":"17613890630298347533"}},"outputId":"d9f7ffef-2e69-4205-b75e-1e5bafa08c3d"},"id":"SgQGMZjYJrxV","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","unzip is already the newest version (6.0-25ubuntu1.1).\n","0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"]}]},{"cell_type":"code","source":["!pip install tokenizers matplotlib sklearn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mabiyQc9Ko7w","executionInfo":{"status":"ok","timestamp":1681971540679,"user_tz":-180,"elapsed":6252,"user":{"displayName":"Gloria Rozovskaya","userId":"17613890630298347533"}},"outputId":"05d20d35-c010-44cc-a619-c4d76db8f96c"},"id":"mabiyQc9Ko7w","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tokenizers\n","  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (3.7.1)\n","Collecting sklearn\n","  Downloading sklearn-0.0.post4.tar.gz (3.6 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (3.0.9)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.22.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.0.7)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (8.4.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (4.39.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (0.11.0)\n","Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (5.12.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Building wheels for collected packages: sklearn\n","  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sklearn: filename=sklearn-0.0.post4-py3-none-any.whl size=2973 sha256=82a88d2dc896c3db7866feee033640044afe38bbc5db5f895a4f4ad67180a010\n","  Stored in directory: /root/.cache/pip/wheels/d5/b2/a9/590d15767d34955f20a9a033e8db973b79cb5672d95790c0a9\n","Successfully built sklearn\n","Installing collected packages: tokenizers, sklearn\n","Successfully installed sklearn-0.0.post4 tokenizers-0.13.3\n"]}]},{"cell_type":"code","source":["!pip install --upgrade jedi==0.17.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZrVB-bHtKrE7","executionInfo":{"status":"ok","timestamp":1681971547066,"user_tz":-180,"elapsed":6409,"user":{"displayName":"Gloria Rozovskaya","userId":"17613890630298347533"}},"outputId":"1a1658fa-1028-4227-df12-52bb8bfcf56b"},"id":"ZrVB-bHtKrE7","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting jedi==0.17.2\n","  Downloading jedi-0.17.2-py2.py3-none-any.whl (1.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting parso<0.8.0,>=0.7.0\n","  Downloading parso-0.7.1-py2.py3-none-any.whl (109 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: parso, jedi\n","  Attempting uninstall: parso\n","    Found existing installation: parso 0.8.3\n","    Uninstalling parso-0.8.3:\n","      Successfully uninstalled parso-0.8.3\n","Successfully installed jedi-0.17.2 parso-0.7.1\n"]}]},{"cell_type":"code","source":["!pip install tokenizers "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h6UT25FcK19l","executionInfo":{"status":"ok","timestamp":1681971551258,"user_tz":-180,"elapsed":4208,"user":{"displayName":"Gloria Rozovskaya","userId":"17613890630298347533"}},"outputId":"5733b164-ae56-4643-aa4a-49b9d56e3da7"},"id":"h6UT25FcK19l","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.9/dist-packages (0.13.3)\n"]}]},{"cell_type":"code","source":["import tensorflow as tf\n","from tokenizers import BertWordPieceTokenizer\n","\n","from tokenizers import Tokenizer\n","from tokenizers.models import WordPiece\n","from tokenizers.pre_tokenizers import Whitespace\n","from tokenizers import normalizers\n","from tokenizers.normalizers import Lowercase\n","from tokenizers.trainers import WordPieceTrainer\n","from tokenizers import decoders\n","\n","import os\n","import re\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n","from string import punctuation\n","from collections import Counter\n","from IPython.display import Image\n","from IPython.core.display import HTML \n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"metadata":{"id":"c4vY-KyNK6Uo"},"id":"c4vY-KyNK6Uo","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru\n","!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en\n","!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.ru\n","!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.en"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xUAFXTnMLwG2","executionInfo":{"status":"ok","timestamp":1681971570796,"user_tz":-180,"elapsed":14239,"user":{"displayName":"Gloria Rozovskaya","userId":"17613890630298347533"}},"outputId":"4b70f05a-3e08-4934-9293-cb58cfeb3724"},"id":"xUAFXTnMLwG2","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-04-20 06:19:15--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru\n","Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n","Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 121340806 (116M)\n","Saving to: ‘opus.en-ru-train.ru’\n","\n","opus.en-ru-train.ru 100%[===================>] 115.72M  20.8MB/s    in 6.4s    \n","\n","2023-04-20 06:19:22 (18.1 MB/s) - ‘opus.en-ru-train.ru’ saved [121340806/121340806]\n","\n","--2023-04-20 06:19:22--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en\n","Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n","Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 67760131 (65M)\n","Saving to: ‘opus.en-ru-train.en’\n","\n","opus.en-ru-train.en 100%[===================>]  64.62M  18.3MB/s    in 4.1s    \n","\n","2023-04-20 06:19:26 (15.9 MB/s) - ‘opus.en-ru-train.en’ saved [67760131/67760131]\n","\n","--2023-04-20 06:19:27--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.ru\n","Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n","Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 305669 (299K)\n","Saving to: ‘opus.en-ru-test.ru’\n","\n","opus.en-ru-test.ru  100%[===================>] 298.50K   534KB/s    in 0.6s    \n","\n","2023-04-20 06:19:28 (534 KB/s) - ‘opus.en-ru-test.ru’ saved [305669/305669]\n","\n","--2023-04-20 06:19:28--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.en\n","Resolving data.statmt.org (data.statmt.org)... 129.215.197.184\n","Connecting to data.statmt.org (data.statmt.org)|129.215.197.184|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 173307 (169K)\n","Saving to: ‘opus.en-ru-test.en’\n","\n","opus.en-ru-test.en  100%[===================>] 169.25K   406KB/s    in 0.4s    \n","\n","2023-04-20 06:19:29 (406 KB/s) - ‘opus.en-ru-test.en’ saved [173307/173307]\n","\n"]}]},{"cell_type":"code","source":["en_sents = open('opus.en-ru-train.en').read().lower().splitlines()\n","ru_sents = open('opus.en-ru-train.ru').read().lower().splitlines()"],"metadata":{"id":"i1kmMnL3L1kZ"},"id":"i1kmMnL3L1kZ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# убеждаемся, что всё работает\n","en_sents[-100], ru_sents[-100]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"znUiSB7-MEIK","executionInfo":{"status":"ok","timestamp":1681971577815,"user_tz":-180,"elapsed":32,"user":{"displayName":"Gloria Rozovskaya","userId":"17613890630298347533"}},"outputId":"a91490be-def4-4d4c-8c10-518ccb7c7eab"},"id":"znUiSB7-MEIK","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('enough for a new life in london?', 'достаточно для новой жизни в лондоне?')"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["tokenizer_en = Tokenizer(WordPiece(), )\n","tokenizer_en.normalizer = normalizers.Sequence([Lowercase()])\n","tokenizer_en.pre_tokenizer = Whitespace()\n","\n","trainer_en = WordPieceTrainer(\n","          vocab_size=30000, special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\"])\n","tokenizer_en.train(files=[\"opus.en-ru-train.en\"], trainer=trainer_en )\n","\n","tokenizer_ru = Tokenizer(WordPiece(), )\n","tokenizer_ru.normalizer = normalizers.Sequence([Lowercase()])\n","tokenizer_ru.pre_tokenizer = Whitespace()\n","\n","trainer_ru = WordPieceTrainer(\n","          vocab_size=30000, special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\"])\n","tokenizer_ru.train(files=[\"opus.en-ru-train.ru\"], trainer=trainer_ru )"],"metadata":{"id":"bqQxEWkpMi3F"},"id":"bqQxEWkpMi3F","execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer_en.decoder = decoders.WordPiece()\n","tokenizer_ru.decoder = decoders.WordPiece()"],"metadata":{"id":"MGfFITshNOrv"},"id":"MGfFITshNOrv","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# раскоментируйте эту ячейку при обучении токенизатора\n","# а потом снова закоментируйте чтобы при перезапуске не перезаписать токенизаторы\n","tokenizer_en.save('tokenizer_en')\n","tokenizer_ru.save('tokenizer_ru')"],"metadata":{"id":"x_VhreObNyv5"},"id":"x_VhreObNyv5","execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer_en = Tokenizer.from_file(\"tokenizer_en\")\n","tokenizer_ru = Tokenizer.from_file(\"tokenizer_ru\")"],"metadata":{"id":"kdOtTUyZN9V_"},"id":"kdOtTUyZN9V_","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def encode(text, tokenizer, target=False):\n","    return [tokenizer.token_to_id('[CLS]')] + tokenizer.encode(text).ids + [tokenizer.token_to_id('[SEP]')]"],"metadata":{"id":"o09f2CusOBSd"},"id":"o09f2CusOBSd","execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_en = [encode(t, tokenizer_en) for t in en_sents]\n","X_ru = [encode(t, tokenizer_ru, target=True) for t in ru_sents]"],"metadata":{"id":"4zJLDi9uOF9L"},"id":"4zJLDi9uOF9L","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# т.к. я оставила значения max_len_en/ru такими, какие они есть (не вводила сама),\n","# понадобилось перевести их значения из numpy.float64 в integer для корректной работы кода\n","\n","max_len_en = int(np.mean([len(x) for x in X_en]))\n","max_len_ru = int(np.mean([len(x) for x in X_ru]))"],"metadata":{"id":"-PrEvDbxOoWA"},"id":"-PrEvDbxOoWA","execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_len_en, max_len_ru"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_EXCeuDOvNY","executionInfo":{"status":"ok","timestamp":1681971723557,"user_tz":-180,"elapsed":13,"user":{"displayName":"Gloria Rozovskaya","userId":"17613890630298347533"}},"outputId":"a8389890-8b51-4528-d6b4-ff1eb27a4e53"},"id":"9_EXCeuDOvNY","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(17, 16)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# важно следить чтобы индекс паддинга совпадал в токенизаторе с value в pad_sequences\n","PAD_IDX = tokenizer_ru.token_to_id('[PAD]')\n","print(PAD_IDX)\n","print(tokenizer_en.token_to_id('[PAD]'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ikYwWKhIOzPX","executionInfo":{"status":"ok","timestamp":1681971723557,"user_tz":-180,"elapsed":12,"user":{"displayName":"Gloria Rozovskaya","userId":"17613890630298347533"}},"outputId":"cfda5472-b847-42af-ec96-111f631ba975"},"id":"ikYwWKhIOzPX","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3\n","3\n"]}]},{"cell_type":"code","source":["# ещё в X_ru_out убрала -1 в maxlen, чтобы у X_en.shape и X_ru_out.shape разница тоже была на 1,\n","# как и в семинарской тетрадке\n","\n","X_en = tf.keras.preprocessing.sequence.pad_sequences(\n","              X_en, maxlen=int(max_len_en), padding='post', value=tokenizer_en.token_to_id('[PAD]'))\n","\n","X_ru_out = tf.keras.preprocessing.sequence.pad_sequences(\n","              [x[1:] for x in X_ru], maxlen=max_len_ru, padding='post', \n","              value=tokenizer_en.token_to_id('[PAD]'))\n","\n","X_ru_dec = tf.keras.preprocessing.sequence.pad_sequences(\n","              [x[:-1] for x in X_ru], maxlen=max_len_ru, \n","              padding='post', value=tokenizer_ru.token_to_id('[PAD]'))"],"metadata":{"id":"awZEZzRlO_W7"},"id":"awZEZzRlO_W7","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# миллион примеров \n","X_en.shape, X_ru_out.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UfcPUP7OPbib","executionInfo":{"status":"ok","timestamp":1681971735168,"user_tz":-180,"elapsed":13,"user":{"displayName":"Gloria Rozovskaya","userId":"17613890630298347533"}},"outputId":"a1bebb3e-e97b-4c68-c317-e0fc47f7a12f"},"id":"UfcPUP7OPbib","execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1000000, 17), (1000000, 16))"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["X_en_train, X_en_valid, X_ru_dec_train, X_ru_dec_valid, X_ru_out_train, X_ru_out_valid = train_test_split(X_en, \n","                                                                                                      X_ru_dec, \n","                                                                                                      X_ru_out, \n","                                                                                                      test_size=0.05)"],"metadata":{"id":"HxTG7ylaP3k2"},"id":"HxTG7ylaP3k2","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def scaled_dot_product_attention(query, key, value, mask):\n","    \"\"\"Calculate the attention weights. \"\"\"\n","    matmul_qk = tf.matmul(query, key, transpose_b=True)\n","\n","    # scale matmul_qk\n","    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n","    logits = matmul_qk / tf.math.sqrt(depth)\n","\n","    # add the mask to zero out padding tokens\n","    if mask is not None:\n","        logits += (mask * -1e9)\n","\n","    # softmax is normalized on the last axis (seq_len_k)\n","    attention_weights = tf.nn.softmax(logits, axis=-1)\n","\n","    output = tf.matmul(attention_weights, value)\n","\n","    return output"],"metadata":{"id":"K31IcVUbQsoJ"},"id":"K31IcVUbQsoJ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","\n","    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n","        super(MultiHeadAttention, self).__init__(name=name)\n","        self.num_heads = num_heads\n","        self.d_model = d_model\n","\n","        assert d_model % self.num_heads == 0\n","\n","        self.depth = d_model // self.num_heads\n","\n","        self.query_dense = tf.keras.layers.Dense(units=d_model)\n","        self.key_dense = tf.keras.layers.Dense(units=d_model)\n","        self.value_dense = tf.keras.layers.Dense(units=d_model)\n","\n","        self.dense = tf.keras.layers.Dense(units=d_model)\n","\n","    def split_heads(self, inputs, batch_size):\n","        inputs = tf.reshape(\n","            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n","        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n","\n","    def call(self, inputs):\n","        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n","            'value'], inputs['mask']\n","        batch_size = tf.shape(query)[0]\n","\n","        # linear layers\n","        query = self.query_dense(query)\n","        key = self.key_dense(key)\n","        value = self.value_dense(value)\n","\n","        # split heads\n","        query = self.split_heads(query, batch_size)\n","        key = self.split_heads(key, batch_size)\n","        value = self.split_heads(value, batch_size)\n","\n","        # scaled dot-product attention\n","        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n","\n","        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n","\n","        # concatenation of heads\n","        concat_attention = tf.reshape(scaled_attention,\n","                                      (batch_size, -1, self.d_model))\n","\n","        # final linear layer\n","        outputs = self.dense(concat_attention)\n","\n","        return outputs"],"metadata":{"id":"Skhs4GhyQv4x"},"id":"Skhs4GhyQv4x","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_padding_mask(x):\n","    mask = tf.cast(tf.math.equal(x, PAD_IDX), tf.float32)\n","    return mask[:, tf.newaxis, tf.newaxis, :]"],"metadata":{"id":"7MWtW0UtRAs6"},"id":"7MWtW0UtRAs6","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_look_ahead_mask(x):\n","    seq_len = tf.shape(x)[1]\n","    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n","    padding_mask = create_padding_mask(x)\n","    return tf.maximum(look_ahead_mask, padding_mask)"],"metadata":{"id":"1XXl2EEBRiV_"},"id":"1XXl2EEBRiV_","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PositionalEncoding(tf.keras.layers.Layer):\n","\n","    def __init__(self, position, d_model):\n","        super(PositionalEncoding, self).__init__()\n","        self.pos_encoding = self.positional_encoding(position, d_model)\n","\n","    def get_angles(self, position, i, d_model):\n","        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n","        return position * angles\n","\n","    def positional_encoding(self, position, d_model):\n","        angle_rads = self.get_angles(\n","        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n","        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n","        d_model=d_model)\n","        sines = tf.math.sin(angle_rads[:, 0::2])\n","        cosines = tf.math.cos(angle_rads[:, 1::2])\n","\n","        pos_encoding = tf.concat([sines, cosines], axis=-1)\n","        pos_encoding = pos_encoding[tf.newaxis, ...]\n","        return tf.cast(pos_encoding, tf.float32)\n","\n","    def call(self, inputs):\n","\n","        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"],"metadata":{"id":"OUuYEbqcRmMG"},"id":"OUuYEbqcRmMG","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n","    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n","    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","    attention = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention\")({\n","          'query': inputs,\n","          'key': inputs,\n","          'value': inputs,\n","          'mask': padding_mask\n","      })\n","    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n","    attention = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(inputs + attention)\n","\n","    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n","    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","    outputs = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention + outputs)\n","\n","    return tf.keras.Model(\n","      inputs=[inputs, padding_mask], outputs=outputs, name=name)"],"metadata":{"id":"g_GyS7bGRqph"},"id":"g_GyS7bGRqph","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def encoder(vocab_size,\n","            num_layers,\n","            units,\n","            d_model,\n","            num_heads,\n","            dropout,\n","            max_len,\n","            name=\"encoder\"):\n","    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n","    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n","\n","    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n","    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n","    embeddings = PositionalEncoding(max_len, d_model)(embeddings)\n","\n","    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n","\n","    for i in range(num_layers):\n","        outputs = encoder_layer(\n","            units=units,\n","            d_model=d_model,\n","            num_heads=num_heads,\n","            dropout=dropout,\n","            name=\"encoder_layer_{}\".format(i),\n","        )([outputs, padding_mask])\n","\n","    return tf.keras.Model(inputs=[inputs, padding_mask], outputs=outputs, name=name)"],"metadata":{"id":"_ubmpbOJRwR9"},"id":"_ubmpbOJRwR9","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n","    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n","    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n","    look_ahead_mask = tf.keras.Input(\n","      shape=(1, None, None), name=\"look_ahead_mask\")\n","    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n","\n","    attention1 = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention_1\")(inputs={\n","          'query': inputs,\n","          'key': inputs,\n","          'value': inputs,\n","          'mask': look_ahead_mask\n","      })\n","    attention1 = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention1 + inputs)\n","\n","    attention2 = MultiHeadAttention(\n","      d_model, num_heads, name=\"attention_2\")(inputs={\n","          'query': attention1,\n","          'key': enc_outputs,\n","          'value': enc_outputs,\n","          'mask': padding_mask\n","      })\n","    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n","    attention2 = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(attention2 + attention1)\n","\n","    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n","    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n","    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n","    outputs = tf.keras.layers.LayerNormalization(\n","      epsilon=1e-6)(outputs + attention2)\n","\n","    return tf.keras.Model(\n","      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n","      outputs=outputs,\n","      name=name)"],"metadata":{"id":"iJrvKMc0R1Pg"},"id":"iJrvKMc0R1Pg","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def decoder(vocab_size,\n","            num_layers,\n","            units,\n","            d_model,\n","            num_heads,\n","            dropout,\n","            max_len,\n","            name='decoder'):\n","    inputs = tf.keras.Input(shape=(None,), name='inputs')\n","    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n","    look_ahead_mask = tf.keras.Input(\n","      shape=(1, None, None), name='look_ahead_mask')\n","    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n","\n","    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n","    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n","    embeddings = PositionalEncoding(max_len, d_model)(embeddings)\n","\n","    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n","\n","    for i in range(num_layers):\n","        outputs = decoder_layer(\n","            units=units,\n","            d_model=d_model,\n","            num_heads=num_heads,\n","            dropout=dropout,\n","            name='decoder_layer_{}'.format(i),\n","        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n","\n","    return tf.keras.Model(\n","      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n","      outputs=outputs,\n","      name=name)"],"metadata":{"id":"Onwfv00BSLd1"},"id":"Onwfv00BSLd1","execution_count":null,"outputs":[]},{"cell_type":"code","source":["def transformer(vocab_size,\n","                num_layers,\n","                units,\n","                d_model,\n","                num_heads,\n","                dropout,\n","                max_len,\n","                name=\"transformer\"):\n","    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n","    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n","\n","    enc_padding_mask = tf.keras.layers.Lambda(\n","      create_padding_mask, output_shape=(1, 1, None),\n","      name='enc_padding_mask')(inputs)\n","    # mask the future tokens for decoder inputs at the 1st attention block\n","    look_ahead_mask = tf.keras.layers.Lambda(\n","      create_look_ahead_mask,\n","      output_shape=(1, None, None),\n","      name='look_ahead_mask')(dec_inputs)\n","    # mask the encoder outputs for the 2nd attention block\n","    dec_padding_mask = tf.keras.layers.Lambda(\n","      create_padding_mask, output_shape=(1, 1, None),\n","      name='dec_padding_mask')(inputs)\n","\n","    enc_outputs = encoder(\n","      vocab_size=vocab_size[0],\n","      num_layers=num_layers,\n","      units=units,\n","      d_model=d_model,\n","      num_heads=num_heads,\n","      dropout=dropout,\n","      max_len=max_len[0],\n","    )(inputs=[inputs, enc_padding_mask])\n","\n","    dec_outputs = decoder(\n","      vocab_size=vocab_size[1],\n","      num_layers=num_layers,\n","      units=units,\n","      d_model=d_model,\n","      num_heads=num_heads,\n","      dropout=dropout,\n","      max_len=max_len[1],\n","    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n","\n","    outputs = tf.keras.layers.Dense(units=vocab_size[1], name=\"outputs\")(dec_outputs)\n","\n","    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"],"metadata":{"id":"0yXTE1t9SPZn"},"id":"0yXTE1t9SPZn","execution_count":null,"outputs":[]},{"cell_type":"code","source":["L  = tf.keras.losses.SparseCategoricalCrossentropy(\n","      from_logits=True, reduction='none',)\n","\n","def loss_function(y_true, y_pred):\n","    loss = L(y_true, y_pred)\n","\n","    mask = tf.cast(tf.not_equal(y_true, PAD_IDX), tf.float32)\n","    loss = tf.multiply(loss, mask)\n","\n","    return tf.reduce_mean(loss)"],"metadata":{"id":"QIcWaVOfSWh4"},"id":"QIcWaVOfSWh4","execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","  def __init__(self, d_model, warmup_steps=4000):\n","    super(CustomSchedule, self).__init__()\n","\n","    self.d_model = d_model\n","    self.d_model = tf.cast(self.d_model, tf.float32)\n","\n","    self.warmup_steps = warmup_steps\n","\n","  def __call__(self, step):\n","    arg1 = tf.math.rsqrt(step)\n","    arg2 = step * (self.warmup_steps ** -1.5)\n","\n","    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"],"metadata":{"id":"3utlf8wGSXn7"},"id":"3utlf8wGSXn7","execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.keras.backend.clear_session()\n","\n","# small model\n","#NUM_LAYERS = 2\n","#D_MODEL = 256\n","#NUM_HEADS = 8\n","#UNITS = 512\n","#DROPOUT = 0.1\n","\n","# параметры с huggingface\n","NUM_LAYERS = 2\n","D_MODEL = 128\n","NUM_HEADS = 8\n","UNITS = 128\n","DROPOUT = 0.1\n","\n","\n","mirrored_strategy = tf.distribute.MirroredStrategy()\n","with mirrored_strategy.scope():\n","    model = transformer(\n","        vocab_size=(tokenizer_en.get_vocab_size(),tokenizer_ru.get_vocab_size()),\n","        num_layers=NUM_LAYERS,\n","        units=UNITS,\n","        d_model=D_MODEL,\n","        num_heads=NUM_HEADS,\n","        dropout=DROPOUT,\n","        max_len=[max_len_en, max_len_ru])\n","\n","    optimizer = tf.keras.optimizers.Adam(\n","        0.001, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n","\n","    def accuracy(y_true, y_pred):\n","        return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n","\n","\n","    model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n","    checkpoint = tf.keras.callbacks.ModelCheckpoint('model_ruen',\n","                                                monitor='val_loss',\n","                                                verbose=1,\n","                                            save_weights_only=True,\n","                                            save_best_only=True,\n","                                            mode='min',\n","                                            save_freq='epoch')"],"metadata":{"id":"gLraQ5sXSiiB"},"id":"gLraQ5sXSiiB","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# помимо текста в модель еще нужно передать целевую последовательность\n","# но не полную а без 1 последнего элемента\n","# а на выходе ожидаем, что модель сгенерирует этот недостающий элемент\n","# мы сравниваем выход из модели с целевой последовательностью уже с этим последним элементом\n","\n","# сдвинутые последовательности создаются выше\n","# X_ru_dec - это переводной текст без последнего элемента\n","# X_ru_out - это переводной текст с последним элементом\n","\n","model.fit((X_en_train, X_ru_dec_train), X_ru_out_train, \n","             validation_data=((X_en_valid, X_ru_dec_valid), X_ru_out_valid),\n","             batch_size=200,\n","             epochs=100,\n","             callbacks=[checkpoint]\n","             )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pFhbgPUxSujR","outputId":"fed142a9-38c4-4415-a4db-e35115b94c41"},"id":"pFhbgPUxSujR","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","2715/2715 [==============================] - ETA: 0s - loss: 2.9675 - accuracy: 0.2343\n","Epoch 1: val_loss improved from inf to 2.25724, saving model to model_ruen\n","2715/2715 [==============================] - 534s 189ms/step - loss: 2.9675 - accuracy: 0.2343 - val_loss: 2.2572 - val_accuracy: 0.2974\n","Epoch 2/100\n","2715/2715 [==============================] - ETA: 0s - loss: 2.1450 - accuracy: 0.3060\n","Epoch 2: val_loss improved from 2.25724 to 1.97648, saving model to model_ruen\n","2715/2715 [==============================] - 433s 160ms/step - loss: 2.1450 - accuracy: 0.3060 - val_loss: 1.9765 - val_accuracy: 0.3258\n","Epoch 3/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.9474 - accuracy: 0.3260\n","Epoch 3: val_loss improved from 1.97648 to 1.88432, saving model to model_ruen\n","2715/2715 [==============================] - 426s 157ms/step - loss: 1.9474 - accuracy: 0.3260 - val_loss: 1.8843 - val_accuracy: 0.3372\n","Epoch 4/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.8545 - accuracy: 0.3361\n","Epoch 4: val_loss improved from 1.88432 to 1.83851, saving model to model_ruen\n","2715/2715 [==============================] - 432s 159ms/step - loss: 1.8545 - accuracy: 0.3361 - val_loss: 1.8385 - val_accuracy: 0.3426\n","Epoch 5/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.7991 - accuracy: 0.3422\n","Epoch 5: val_loss improved from 1.83851 to 1.81238, saving model to model_ruen\n","2715/2715 [==============================] - 423s 156ms/step - loss: 1.7991 - accuracy: 0.3422 - val_loss: 1.8124 - val_accuracy: 0.3462\n","Epoch 6/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.7613 - accuracy: 0.3465\n","Epoch 6: val_loss improved from 1.81238 to 1.78631, saving model to model_ruen\n","2715/2715 [==============================] - 421s 155ms/step - loss: 1.7613 - accuracy: 0.3465 - val_loss: 1.7863 - val_accuracy: 0.3495\n","Epoch 7/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.7337 - accuracy: 0.3497\n","Epoch 7: val_loss improved from 1.78631 to 1.77240, saving model to model_ruen\n","2715/2715 [==============================] - 421s 155ms/step - loss: 1.7337 - accuracy: 0.3497 - val_loss: 1.7724 - val_accuracy: 0.3514\n","Epoch 8/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.7132 - accuracy: 0.3522\n","Epoch 8: val_loss improved from 1.77240 to 1.76542, saving model to model_ruen\n","2715/2715 [==============================] - 421s 155ms/step - loss: 1.7132 - accuracy: 0.3522 - val_loss: 1.7654 - val_accuracy: 0.3521\n","Epoch 9/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.6961 - accuracy: 0.3541\n","Epoch 9: val_loss improved from 1.76542 to 1.75995, saving model to model_ruen\n","2715/2715 [==============================] - 421s 155ms/step - loss: 1.6961 - accuracy: 0.3541 - val_loss: 1.7600 - val_accuracy: 0.3536\n","Epoch 10/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.6828 - accuracy: 0.3557\n","Epoch 10: val_loss improved from 1.75995 to 1.74854, saving model to model_ruen\n","2715/2715 [==============================] - 428s 158ms/step - loss: 1.6828 - accuracy: 0.3557 - val_loss: 1.7485 - val_accuracy: 0.3544\n","Epoch 11/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.6707 - accuracy: 0.3573\n","Epoch 11: val_loss did not improve from 1.74854\n","2715/2715 [==============================] - 419s 154ms/step - loss: 1.6707 - accuracy: 0.3573 - val_loss: 1.7501 - val_accuracy: 0.3551\n","Epoch 12/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.6603 - accuracy: 0.3584\n","Epoch 12: val_loss did not improve from 1.74854\n","2715/2715 [==============================] - 426s 157ms/step - loss: 1.6603 - accuracy: 0.3584 - val_loss: 1.7514 - val_accuracy: 0.3552\n","Epoch 13/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.6511 - accuracy: 0.3594\n","Epoch 13: val_loss improved from 1.74854 to 1.73988, saving model to model_ruen\n","2715/2715 [==============================] - 427s 157ms/step - loss: 1.6511 - accuracy: 0.3594 - val_loss: 1.7399 - val_accuracy: 0.3567\n","Epoch 14/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.6427 - accuracy: 0.3605\n","Epoch 14: val_loss improved from 1.73988 to 1.73216, saving model to model_ruen\n","2715/2715 [==============================] - 420s 155ms/step - loss: 1.6427 - accuracy: 0.3605 - val_loss: 1.7322 - val_accuracy: 0.3573\n","Epoch 15/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.6352 - accuracy: 0.3614\n","Epoch 15: val_loss improved from 1.73216 to 1.73193, saving model to model_ruen\n","2715/2715 [==============================] - 420s 155ms/step - loss: 1.6352 - accuracy: 0.3614 - val_loss: 1.7319 - val_accuracy: 0.3574\n","Epoch 16/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.6287 - accuracy: 0.3621\n","Epoch 16: val_loss did not improve from 1.73193\n","2715/2715 [==============================] - 419s 154ms/step - loss: 1.6287 - accuracy: 0.3621 - val_loss: 1.7323 - val_accuracy: 0.3581\n","Epoch 17/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.6231 - accuracy: 0.3628\n","Epoch 17: val_loss improved from 1.73193 to 1.72843, saving model to model_ruen\n","2715/2715 [==============================] - 421s 155ms/step - loss: 1.6231 - accuracy: 0.3628 - val_loss: 1.7284 - val_accuracy: 0.3586\n","Epoch 18/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.6180 - accuracy: 0.3633\n","Epoch 18: val_loss improved from 1.72843 to 1.72454, saving model to model_ruen\n","2715/2715 [==============================] - 420s 155ms/step - loss: 1.6180 - accuracy: 0.3633 - val_loss: 1.7245 - val_accuracy: 0.3588\n","Epoch 19/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.6136 - accuracy: 0.3640\n","Epoch 19: val_loss did not improve from 1.72454\n","2715/2715 [==============================] - 422s 155ms/step - loss: 1.6136 - accuracy: 0.3640 - val_loss: 1.7260 - val_accuracy: 0.3594\n","Epoch 20/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.6090 - accuracy: 0.3644\n","Epoch 20: val_loss did not improve from 1.72454\n","2715/2715 [==============================] - 423s 156ms/step - loss: 1.6090 - accuracy: 0.3644 - val_loss: 1.7254 - val_accuracy: 0.3596\n","Epoch 21/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.6054 - accuracy: 0.3649\n","Epoch 21: val_loss did not improve from 1.72454\n","2715/2715 [==============================] - 423s 156ms/step - loss: 1.6054 - accuracy: 0.3649 - val_loss: 1.7256 - val_accuracy: 0.3598\n","Epoch 22/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.6021 - accuracy: 0.3653\n","Epoch 22: val_loss improved from 1.72454 to 1.72077, saving model to model_ruen\n","2715/2715 [==============================] - 422s 155ms/step - loss: 1.6021 - accuracy: 0.3653 - val_loss: 1.7208 - val_accuracy: 0.3602\n","Epoch 23/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5990 - accuracy: 0.3657\n","Epoch 23: val_loss did not improve from 1.72077\n","2715/2715 [==============================] - 422s 155ms/step - loss: 1.5990 - accuracy: 0.3657 - val_loss: 1.7222 - val_accuracy: 0.3597\n","Epoch 24/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5955 - accuracy: 0.3661\n","Epoch 24: val_loss improved from 1.72077 to 1.71866, saving model to model_ruen\n","2715/2715 [==============================] - 423s 156ms/step - loss: 1.5955 - accuracy: 0.3661 - val_loss: 1.7187 - val_accuracy: 0.3601\n","Epoch 25/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5927 - accuracy: 0.3665\n","Epoch 25: val_loss did not improve from 1.71866\n","2715/2715 [==============================] - 422s 155ms/step - loss: 1.5927 - accuracy: 0.3665 - val_loss: 1.7200 - val_accuracy: 0.3601\n","Epoch 26/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5898 - accuracy: 0.3668\n","Epoch 26: val_loss did not improve from 1.71866\n","2715/2715 [==============================] - 422s 155ms/step - loss: 1.5898 - accuracy: 0.3668 - val_loss: 1.7191 - val_accuracy: 0.3605\n","Epoch 27/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5874 - accuracy: 0.3672\n","Epoch 27: val_loss improved from 1.71866 to 1.71748, saving model to model_ruen\n","2715/2715 [==============================] - 423s 156ms/step - loss: 1.5874 - accuracy: 0.3672 - val_loss: 1.7175 - val_accuracy: 0.3606\n","Epoch 28/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5841 - accuracy: 0.3676\n","Epoch 28: val_loss improved from 1.71748 to 1.71524, saving model to model_ruen\n","2715/2715 [==============================] - 424s 156ms/step - loss: 1.5841 - accuracy: 0.3676 - val_loss: 1.7152 - val_accuracy: 0.3607\n","Epoch 29/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5822 - accuracy: 0.3677\n","Epoch 29: val_loss improved from 1.71524 to 1.71521, saving model to model_ruen\n","2715/2715 [==============================] - 432s 159ms/step - loss: 1.5822 - accuracy: 0.3677 - val_loss: 1.7152 - val_accuracy: 0.3610\n","Epoch 30/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5798 - accuracy: 0.3679\n","Epoch 30: val_loss improved from 1.71521 to 1.71069, saving model to model_ruen\n","2715/2715 [==============================] - 423s 156ms/step - loss: 1.5798 - accuracy: 0.3679 - val_loss: 1.7107 - val_accuracy: 0.3610\n","Epoch 31/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5778 - accuracy: 0.3682\n","Epoch 31: val_loss improved from 1.71069 to 1.70811, saving model to model_ruen\n","2715/2715 [==============================] - 422s 155ms/step - loss: 1.5778 - accuracy: 0.3682 - val_loss: 1.7081 - val_accuracy: 0.3613\n","Epoch 32/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5757 - accuracy: 0.3684\n","Epoch 32: val_loss did not improve from 1.70811\n","2715/2715 [==============================] - 421s 155ms/step - loss: 1.5757 - accuracy: 0.3684 - val_loss: 1.7140 - val_accuracy: 0.3612\n","Epoch 33/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5736 - accuracy: 0.3687\n","Epoch 33: val_loss did not improve from 1.70811\n","2715/2715 [==============================] - 420s 155ms/step - loss: 1.5736 - accuracy: 0.3687 - val_loss: 1.7160 - val_accuracy: 0.3619\n","Epoch 34/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5719 - accuracy: 0.3689\n","Epoch 34: val_loss did not improve from 1.70811\n","2715/2715 [==============================] - 422s 155ms/step - loss: 1.5719 - accuracy: 0.3689 - val_loss: 1.7118 - val_accuracy: 0.3618\n","Epoch 35/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5701 - accuracy: 0.3692\n","Epoch 35: val_loss did not improve from 1.70811\n","2715/2715 [==============================] - 423s 156ms/step - loss: 1.5701 - accuracy: 0.3692 - val_loss: 1.7096 - val_accuracy: 0.3617\n","Epoch 36/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5683 - accuracy: 0.3693\n","Epoch 36: val_loss did not improve from 1.70811\n","2715/2715 [==============================] - 422s 155ms/step - loss: 1.5683 - accuracy: 0.3693 - val_loss: 1.7117 - val_accuracy: 0.3615\n","Epoch 37/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5668 - accuracy: 0.3695\n","Epoch 37: val_loss did not improve from 1.70811\n","2715/2715 [==============================] - 422s 155ms/step - loss: 1.5668 - accuracy: 0.3695 - val_loss: 1.7084 - val_accuracy: 0.3622\n","Epoch 38/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5650 - accuracy: 0.3696\n","Epoch 38: val_loss did not improve from 1.70811\n","2715/2715 [==============================] - 424s 156ms/step - loss: 1.5650 - accuracy: 0.3696 - val_loss: 1.7229 - val_accuracy: 0.3608\n","Epoch 39/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5635 - accuracy: 0.3699\n","Epoch 39: val_loss did not improve from 1.70811\n","2715/2715 [==============================] - 431s 159ms/step - loss: 1.5635 - accuracy: 0.3699 - val_loss: 1.7181 - val_accuracy: 0.3620\n","Epoch 40/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5626 - accuracy: 0.3700\n","Epoch 40: val_loss did not improve from 1.70811\n","2715/2715 [==============================] - 420s 155ms/step - loss: 1.5626 - accuracy: 0.3700 - val_loss: 1.7119 - val_accuracy: 0.3622\n","Epoch 41/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5608 - accuracy: 0.3701\n","Epoch 41: val_loss did not improve from 1.70811\n","2715/2715 [==============================] - 426s 157ms/step - loss: 1.5608 - accuracy: 0.3701 - val_loss: 1.7104 - val_accuracy: 0.3623\n","Epoch 42/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5593 - accuracy: 0.3702\n","Epoch 42: val_loss did not improve from 1.70811\n","2715/2715 [==============================] - 422s 155ms/step - loss: 1.5593 - accuracy: 0.3702 - val_loss: 1.7107 - val_accuracy: 0.3621\n","Epoch 43/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5580 - accuracy: 0.3704\n","Epoch 43: val_loss did not improve from 1.70811\n","2715/2715 [==============================] - 421s 155ms/step - loss: 1.5580 - accuracy: 0.3704 - val_loss: 1.7110 - val_accuracy: 0.3623\n","Epoch 44/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5568 - accuracy: 0.3705\n","Epoch 44: val_loss did not improve from 1.70811\n","2715/2715 [==============================] - 421s 155ms/step - loss: 1.5568 - accuracy: 0.3705 - val_loss: 1.7121 - val_accuracy: 0.3620\n","Epoch 45/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5553 - accuracy: 0.3707\n","Epoch 45: val_loss did not improve from 1.70811\n","2715/2715 [==============================] - 421s 155ms/step - loss: 1.5553 - accuracy: 0.3707 - val_loss: 1.7081 - val_accuracy: 0.3618\n","Epoch 46/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5543 - accuracy: 0.3708\n","Epoch 46: val_loss did not improve from 1.70811\n","2715/2715 [==============================] - 421s 155ms/step - loss: 1.5543 - accuracy: 0.3708 - val_loss: 1.7090 - val_accuracy: 0.3623\n","Epoch 47/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5528 - accuracy: 0.3709\n","Epoch 47: val_loss did not improve from 1.70811\n","2715/2715 [==============================] - 420s 155ms/step - loss: 1.5528 - accuracy: 0.3709 - val_loss: 1.7127 - val_accuracy: 0.3619\n","Epoch 48/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5516 - accuracy: 0.3711\n","Epoch 48: val_loss did not improve from 1.70811\n","2715/2715 [==============================] - 423s 156ms/step - loss: 1.5516 - accuracy: 0.3711 - val_loss: 1.7118 - val_accuracy: 0.3622\n","Epoch 49/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5504 - accuracy: 0.3712\n","Epoch 49: val_loss did not improve from 1.70811\n","2715/2715 [==============================] - 421s 155ms/step - loss: 1.5504 - accuracy: 0.3712 - val_loss: 1.7092 - val_accuracy: 0.3624\n","Epoch 50/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5491 - accuracy: 0.3714\n","Epoch 50: val_loss did not improve from 1.70811\n","2715/2715 [==============================] - 420s 155ms/step - loss: 1.5491 - accuracy: 0.3714 - val_loss: 1.7108 - val_accuracy: 0.3624\n","Epoch 51/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5483 - accuracy: 0.3714\n","Epoch 51: val_loss improved from 1.70811 to 1.70716, saving model to model_ruen\n","2715/2715 [==============================] - 421s 155ms/step - loss: 1.5483 - accuracy: 0.3714 - val_loss: 1.7072 - val_accuracy: 0.3621\n","Epoch 52/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5475 - accuracy: 0.3715\n","Epoch 52: val_loss did not improve from 1.70716\n","2715/2715 [==============================] - 420s 155ms/step - loss: 1.5475 - accuracy: 0.3715 - val_loss: 1.7157 - val_accuracy: 0.3618\n","Epoch 53/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5464 - accuracy: 0.3716\n","Epoch 53: val_loss did not improve from 1.70716\n","2715/2715 [==============================] - 420s 155ms/step - loss: 1.5464 - accuracy: 0.3716 - val_loss: 1.7098 - val_accuracy: 0.3624\n","Epoch 54/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5458 - accuracy: 0.3717\n","Epoch 54: val_loss improved from 1.70716 to 1.70561, saving model to model_ruen\n","2715/2715 [==============================] - 422s 155ms/step - loss: 1.5458 - accuracy: 0.3717 - val_loss: 1.7056 - val_accuracy: 0.3628\n","Epoch 55/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5447 - accuracy: 0.3718\n","Epoch 55: val_loss did not improve from 1.70561\n","2715/2715 [==============================] - 430s 158ms/step - loss: 1.5447 - accuracy: 0.3718 - val_loss: 1.7135 - val_accuracy: 0.3624\n","Epoch 56/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5438 - accuracy: 0.3719\n","Epoch 56: val_loss did not improve from 1.70561\n","2715/2715 [==============================] - 420s 155ms/step - loss: 1.5438 - accuracy: 0.3719 - val_loss: 1.7155 - val_accuracy: 0.3626\n","Epoch 57/100\n","2715/2715 [==============================] - ETA: 0s - loss: 1.5432 - accuracy: 0.3720\n","Epoch 57: val_loss did not improve from 1.70561\n","2715/2715 [==============================] - 420s 155ms/step - loss: 1.5432 - accuracy: 0.3720 - val_loss: 1.7087 - val_accuracy: 0.3629\n","Epoch 58/100\n"," 201/2715 [=>............................] - ETA: 6:15 - loss: 1.4753 - accuracy: 0.3773"]}]},{"cell_type":"code","source":["def translate(text):\n","    input_ids = encode(text.lower(), tokenizer_en)\n","\n","    input_ids = tf.keras.preprocessing.sequence.pad_sequences(\n","                                      [input_ids], maxlen=max_len_en, padding='post')\n","\n","    \n","    \n","    output_ids = [tokenizer_ru.token_to_id('[CLS]') ]\n","    \n","    pred = model((input_ids, tf.cast([output_ids], tf.int32)), training=False)\n"," \n","    \n","    while pred.numpy().argmax(2)[0][-1] not in [tokenizer_ru.token_to_id('[SEP]'), \n","                                                            ]:\n","        if len(output_ids) > max_len_ru:\n","            break\n","        output_ids.append(pred.numpy().argmax(2)[0][-1])\n","        pred = model((input_ids, tf.cast([output_ids], tf.int32)), training=False)\n","\n","    return tokenizer_ru.decode(output_ids[1:])"],"metadata":{"id":"Fx9xAQiYX1UZ"},"id":"Fx9xAQiYX1UZ","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# проверяем, всё ли работает\n","translate(\"can you translate this sentence?\")"],"metadata":{"id":"uDkwwKtcX1ow"},"id":"uDkwwKtcX1ow","execution_count":null,"outputs":[]},{"cell_type":"code","source":["en_sents_test = open('opus.en-ru-test.en').read().lower().splitlines()\n","ru_sents_test = open('opus.en-ru-test.ru').read().lower().splitlines()"],"metadata":{"id":"JZD4UnDMYSLK"},"id":"JZD4UnDMYSLK","execution_count":null,"outputs":[]},{"cell_type":"code","source":["translations = []\n","\n","for i in range(len(en_sents_test)):\n","  translations.append(translate(en_sents_test[i]))"],"metadata":{"id":"bUgwAP9LYyfS"},"id":"bUgwAP9LYyfS","execution_count":null,"outputs":[]},{"cell_type":"code","source":["bleus = []\n","\n","for i, t in enumerate(translations):\n","  reference = tokenizer_ru.encode(t).tokens\n","  hypothesis = tokenizer_ru.encode(ru_sents_test[i]).tokens\n","\n","bleus.append(nltk.translate.bleu_score.sentence_bleu([reference], hypothesis,  ))"],"metadata":{"id":"XaWf24doZRwH"},"id":"XaWf24doZRwH","execution_count":null,"outputs":[]},{"cell_type":"code","source":["(sum(bleus)/len(bleus))*100"],"metadata":{"id":"0FP2zo7yaDv0"},"id":"0FP2zo7yaDv0","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"b5aa93d6","metadata":{"id":"b5aa93d6"},"source":["\n","## Задание 2 (2 балла).\n","Прочитайте главу про машинный перевод у Журафски и Маннига - https://web.stanford.edu/~jurafsky/slp3/10.pdf \n","Ответьте своими словами в чем заключается техника back translation? Для чего она применяется и что позволяет получить? Опишите по шагам как его применить к паре en-ru на данных из семинара. "]},{"cell_type":"markdown","source":["*Честно скажу, что прочитала всю главу и не нашла там информации по этому вопросу, поэтому обратилась к интернету и ниже пересказываю прочитанное там....*\n","\n","Back translation (или \"обратный перевод\") - метод улучшения качества машинного перевода путём создания дополнительных синтетических данных. Например, у нас есть параллельный корпус данных en-ru и мы хотим обучить модель переводить предложения с английского на русский. Применяя метод обратного перевода, мы сначала обучаем модель переводить с русского на английский, используя наши параллельные данные. Когда мы это сделали, мы можем найти корпус текстов только для русского и перевести его с помощью нашей модели на английский, тем самым получив дополнительный синтетический параллельный корпус данных. Новые синтетические данные можно смешать с уже имевшимися и обучить модель снова. Качество перевода обещает значительно улучшиться!"],"metadata":{"id":"tAerv6XDXDhG"},"id":"tAerv6XDXDhG"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.12"},"colab":{"provenance":[]},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}