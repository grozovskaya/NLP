{"cells":[{"cell_type":"markdown","metadata":{"id":"00fad453"},"source":["# Домашнее задание № 4. Языковые модели"],"id":"00fad453"},{"cell_type":"markdown","metadata":{"id":"5d056af4"},"source":["## Задание 1 (8 баллов)."],"id":"5d056af4"},{"cell_type":"markdown","metadata":{"id":"d1f532a8"},"source":["В семинаре для генерации мы использовали предположение маркова и считали, что слово зависит только от 1 предыдущего слова. Но ничто нам не мешает попробовать увеличить размер окна и учитывать два или даже три прошлых слова. Для них мы еще сможем собрать достаточно статистик и, логично предположить, что качество сгенерированного текста должно вырасти."],"id":"d1f532a8"},{"cell_type":"markdown","metadata":{"id":"de743d1d"},"source":["Попробуйте сделать языковую модель, которая будет учитывать два предыдущих слова при генерации текста.\n","Сгенерируйте несколько текстов (3-5) и расчитайте перплексию получившейся модели.\n","Можно использовать данные из семинара или любые другие (сопоставимые или большие по объему). Перплексию рассчитывайте на 10-50 отложенных предложениях (они не должны использоваться при сборе статистик).\n","\n","\n","Подсказки:\n","    - нужно будет добавить еще один тэг <start>\n","    - еще одна матрица не нужна, можно по строкам хронить биграмы, а по колонкам униграммы\n","    - тексты должны быть очень похожи на нормальные (если у вас получается рандомная каша, вы что-то делаете не так)."],"id":"de743d1d"},{"cell_type":"code","execution_count":null,"metadata":{"id":"d078056d","outputId":"e3266580-5640-4545-f00e-14bbe0e031c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: razdel in c:\\users\\sara7\\anaconda3\\lib\\site-packages (0.5.0)\n"]}],"source":["!pip install razdel"],"id":"d078056d"},{"cell_type":"code","execution_count":null,"metadata":{"id":"_YijnK8Ia-L-"},"outputs":[],"source":["from string import punctuation\n","from razdel import sentenize\n","from razdel import tokenize as razdel_tokenize\n","import numpy as np\n","from IPython.display import Image\n","from IPython.core.display import HTML"],"id":"_YijnK8Ia-L-"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3WCIHja_a-MA"},"outputs":[],"source":["from collections import Counter"],"id":"3WCIHja_a-MA"},{"cell_type":"code","execution_count":null,"metadata":{"id":"C8oF1FVba-MB"},"outputs":[],"source":["from nltk.tokenize import sent_tokenize"],"id":"C8oF1FVba-MB"},{"cell_type":"code","execution_count":null,"metadata":{"id":"azMpMYtQa-MC"},"outputs":[],"source":["from scipy.sparse import lil_matrix"],"id":"azMpMYtQa-MC"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mp9xpmeja-MC"},"outputs":[],"source":["news = open('lenta.txt', encoding='utf-8').read()"],"id":"Mp9xpmeja-MC"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Q9kYFcaa-MD"},"outputs":[],"source":["def normalize(text):\n","    normalized_text = [word.text.strip(punctuation) for word \\\n","                                                            in razdel_tokenize(text)]\n","    normalized_text = [word.lower() for word in normalized_text if word and len(word) < 20 ]\n","    return normalized_text"],"id":"9Q9kYFcaa-MD"},{"cell_type":"code","execution_count":null,"metadata":{"id":"qd5Qnezga-MD"},"outputs":[],"source":["sentences_news = [['<start>','<start>'] + normalize(text) + ['<end>'] for text in sent_tokenize(news)]"],"id":"qd5Qnezga-MD"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ddDT-aA1a-MD"},"outputs":[],"source":["test_news = sentences_news[:50]\n","train_news = sentences_news[50:]"],"id":"ddDT-aA1a-MD"},{"cell_type":"code","execution_count":null,"metadata":{"id":"UOm4Walra-ME"},"outputs":[],"source":["def ngrammer(tokens, n):\n","    ngrams = []\n","    for i in range(0,len(tokens)-n+1):\n","        ngrams.append(' '.join(tokens[i:i+n]))\n","    return ngrams"],"id":"UOm4Walra-ME"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z9vYpGz4a-ME"},"outputs":[],"source":["unigrams_news = Counter()\n","bigrams_news = Counter()\n","trigrams_news = Counter()\n","\n","for sentence in train_news:\n","    unigrams_news.update(sentence)\n","    bigrams_news.update(ngrammer(sentence, n=2))\n","    trigrams_news.update(ngrammer(sentence, n=3))"],"id":"Z9vYpGz4a-ME"},{"cell_type":"code","execution_count":null,"metadata":{"id":"t6C7kgypa-ME"},"outputs":[],"source":["# матрица слова на биграммы (инициализируем нулями)\n","matrix_news = lil_matrix((len(bigrams_news),\n","                         len(unigrams_news)))\n","\n","# к матрице нужно обращаться по индексам\n","# поэтому зафиксируем порядок слов в словаре и сделаем маппинг id-слово и слово-id\n","id2word_news = list(unigrams_news)\n","word2id_news = {word:i for i, word in enumerate(id2word_news)}\n","\n","# то же самое для биграмм\n","id2bigram_news = list(bigrams_news)\n","bigram2id_news = {word:i for i, word in enumerate(id2bigram_news)}"],"id":"t6C7kgypa-ME"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z-G_tWy4a-ME"},"outputs":[],"source":["# заполняем матрицу\n","for trigram in trigrams_news:\n","    word1, word2, word3 = trigram.split()\n","    bigram = word1+' '+word2\n","    # на пересечение биграмм и слов ставим вероятность встретить второе после первого\n","    # вероятность встретить слова после биграммы\n","    matrix_news[bigram2id_news[bigram], word2id_news[word3]] =  (trigrams_news[trigram]/\n","                                                                     bigrams_news[bigram])"],"id":"Z-G_tWy4a-ME"},{"cell_type":"code","execution_count":null,"metadata":{"id":"wfWqTF25a-MF"},"outputs":[],"source":["# Для генерации нам понадобится функция np.random.choice,\n","# которая выбирает случайный объект из заданных.\n","# Ещё в неё можно подать вероятность каждого объекта\n","# и она будет доставать по ним (не только максимальный по вероятности)\n","\n","def generate(matrix, id2bigram, id2word, bigram2id, n=100, start='<start> <start>'):\n","    text = []\n","    current_id = bigram2id[start]\n","    for i in range(n):\n","        chosen = np.random.choice(matrix.shape[1], p=matrix[current_id].toarray()[0])\n","\n","# просто выбирать наиболее вероятное продолжение не получится\n","# можете попробовать раскоментировать следующую строчку и посмотреть что получается\n","# в современных языковых моделях есть специальный параметр, который\n","# позволяет регулировать разнообразность/случайность генерации\n","# он называется температура, чем выше температура тем ближе будет к argmax\n","# чем меньше температура тем ближе к полностью рандомной генерации\n","        #chosen = matrix[current_id].toarray().argmax()\n","\n","        text.append(id2word[chosen])\n","\n","        if id2word[chosen] == '<end>':\n","            current_id = bigram2id[start]\n","        else:\n","            current_bigram = id2bigram[current_id]\n","            second_word = current_bigram.split()[1]\n","            next_text = second_word + ' ' + id2word[chosen]\n","            current_id = bigram2id[next_text]\n","\n","    return ' '.join(text)"],"id":"wfWqTF25a-MF"},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"asb-_z3ta-MF","outputId":"a5f362ce-3569-4bd5-e8d3-ded2c88036d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["1\n","по данным интерфакса видеозапись была сделанная грузинскими спецслужбами \n"," по словам савчука штатная численность отдела составит 50 процентов голосов избирателей принявших участие в референдуме граждан рф поскольку никаких специальных мер по оказанию помощи палестинским беженцам unrwa в лагере беженцев айн эль-хельва в пригороде лос-анджелеса куда они прибыли на северный кавказ в плацдарм священной войны газават \n"," в общем-то мы этим и приступили к обыскам на даче генпрокурора в течение часа летать кругами чтобы выработать общую позицию со странами снг более года \n"," нам надо будет за пределами афганистана российская сторона утверждает что причины гибели военнослужащих и членов экипажа \n"," похоронен\n","2\n","вместе с руководством кпрф \n"," по имеющимся сведениям патентообладатели все-таки не включен в общефедеральный список сталинского блока житель нарвы юрий мишин баллотируется по списку лдпр \n"," иосиро мори \n"," устаналиваются тарифные квоты на добычу нефти на заводы внутри страны \n"," в связи с эти президент еще раз что речь о введении в стране сети пунктов употребления наркотиков противоречит соответствующим международным конвенциям следующие выборы главы администрации одного из российских и зарубежных держателей кредитных карт незаконные продажи медикаментов или программного обеспечения в частности итальянский персонал железнодорожных войск и милицейского спецназа \n"," причем пистолеты будут выданы каждому судебному приставу а автоматы для продажи\n","3\n","в масштабах избирательных округов и их сосед 11-летний школьник борис горячев все трое погибли \n"," в ее состав как ожидается госдума рассмотрит этот документ был снабжен рядом секретных грифов и кодом сх 95/53452 \n"," в частности по поводу как компьютерное хулиганство которое не исполнено в положенный срок в пятницу однако из-за плохой видимости и сильного ветра огонь перекинулся на другую работу сообщает риа новости вызванный кинолог подтвердил что небольшая группа российских юристов во главе чечни на высоте 300 метров \n"," если я не стал уточнять каков именно размер денежного иска отметив что эти ограничения защищают репутацию подозреваемых позволяют сохранить в\n","4\n","согласно завещанию эсамбаев уроженец чеченского села старые атаги \n"," посол грузии в нью-йорке завершились двухдневные торги аукционного дома christie s торги были прекращены до завершения отопительного сезона \n"," по его мнению есть все основания подозревать владельца “ жигулей ” в причастности к заказным убийствам своих ближайших соратников и охранников погибли \n"," начальник пресс-центра объединенной группировки войск на северном кавказе \n"," в настоящее время избирательные участки \n"," в марте 2000 года \n"," все они обвинялись в совершении преступления утром во вторник сообщил старший координатор госдепартамента сша на 72-м году жизни скончался выдающийся российский лауреат государственной премии в области реализации государственной политики\n","5\n","московское правительство работает не покладая рук 16 ноября истекает последний срок назначенный европейской комиссией по политическим мотивам \n"," в его медицинских познаниях что готов завершить свою карьеру уйти с поста члена совета директоров аэрофлота которое планируется провести дальнейшее расследование по обвинению в провозе взрывного устройства \n"," россия подчеркнула верховный комиссар оон по наблюдению за интернетом проект постановления палаты заседанию госдумы будет осуществлять пограничный контроль с шенгенскими странами в последнее время пограничники все чаще сообщают не в первый день работы нового состава кабинета министров и теперь проблема чечни должна решаться политическим путем \n"," в 1993 году киселев покинул « останкино »\n"]}],"source":["for i in range(5):\n","    text = generate(matrix_news, id2bigram_news,\n","               id2word_news, bigram2id_news, n=100, start='<start> <start>').replace('<end>', '\\n')\n","    print(i+1)\n","    print(text)"],"id":"asb-_z3ta-MF"},{"cell_type":"markdown","metadata":{"id":"mcNib-oha-MG"},"source":["Считаем перплексию:"],"id":"mcNib-oha-MG"},{"cell_type":"code","execution_count":null,"metadata":{"id":"MLMOM2OKa-MG"},"outputs":[],"source":["# Мы уже видели что произведение вероятностей можно заменить на экспоненту суммы логарифмов\n","# С возведением в степень тоже есть удобное правило - log(x^y) = y * log(x)\n","# можно заменить вот такую функцию (она ожидает вероятность)\n","# def perplexity(p, N):\n","#     return p**(-1/N)\n","\n","\n","# на вот такую (результат должен совпадать)\n","# функция ожидает логарифм вероятности\n","\n","def perplexity(logp, N):\n","    return np.exp((-1/N) * logp)"],"id":"MLMOM2OKa-MG"},{"cell_type":"code","execution_count":null,"metadata":{"id":"kGeAQ4w9a-MG"},"outputs":[],"source":["def compute_join_proba_markov_assumption(text, word_counts, bigram_counts):\n","    prob = 0\n","    tokens = normalize(text)\n","    for ngram in ngrammer(['<start>'] + tokens + ['<end>'],2):\n","        word1, word2 = ngram.split()\n","        if word1 in word_counts and ngram in bigram_counts:\n","            prob += np.log(bigram_counts[ngram]/word_counts[word1])\n","        else:\n","            prob += np.log(2e-5)\n","\n","    return prob, len(tokens)"],"id":"kGeAQ4w9a-MG"},{"cell_type":"code","execution_count":null,"metadata":{"id":"rYlyngG_a-MH","outputId":"6628f70c-d8ce-437e-847f-c2973622f367"},"outputs":[{"name":"stdout","output_type":"stream","text":["20610.830649491192\n"]}],"source":["p = []\n","for sent in test_news:\n","    text = ' '.join(sent)\n","    p.append(perplexity(*compute_join_proba_markov_assumption(text, unigrams_news, bigrams_news)))\n","print(np.mean(p))"],"id":"rYlyngG_a-MH"},{"cell_type":"markdown","metadata":{"id":"8e0a8dd5"},"source":["## Задание № 2* (2 балла)."],"id":"8e0a8dd5"},{"cell_type":"markdown","metadata":{"id":"0b36c44b"},"source":["Прочитайте главу про языковое моделирование в книге Журафски и Мартина - https://web.stanford.edu/~jurafsky/slp3/3.pdf"],"id":"0b36c44b"},{"cell_type":"markdown","metadata":{"id":"5d9b1bd8"},"source":["Развернуто (в пределах 1000 знаков) ответьте на вопросы (по-русски):"],"id":"5d9b1bd8"},{"cell_type":"markdown","metadata":{"id":"0c2cf844"},"source":["**1. Что можно делать с проблемой несловарных слов? В семинаре мы просто использовали какое-то маленькое значение вероятности, а какие есть другие способы?**"],"id":"0c2cf844"},{"cell_type":"markdown","metadata":{"id":"fzXGE4hXYtwR"},"source":["Несловарные (неизвестные) слова принято называть out of vocabulary (OOV) words. Процентное содержание таких слов в тексте (по сравнению с известным нам закрытым словарём) называется OOV rate.\n","\n","Один из способов решить проблему с неизвестными словами заключается в том, чтобы добавить в наш закрытый словарь псевдо-слова, которые обозначаются как <UNK>. Таким образом создатся система с открытым словарём.\n","\n","Если у нас нет заранее собранного закрытого словаря, мы можем собрать его, заменяя при этом особенно редкие слова на <UNK>.\n","\n","И в том, и в другом случае полученный открытый словарь мы в дальнейшем используем для обучения модели. В процессе обучения мы относимся к <UNK> как к обычному слову и точно так же считаем вероятность встретить его, как для любого другого слова."],"id":"fzXGE4hXYtwR"},{"cell_type":"markdown","metadata":{"id":"d1d1c152"},"source":["**2. Что такое сглаживание (smoothing)?**"],"id":"d1d1c152"},{"cell_type":"markdown","metadata":{"id":"EOix1KMorscO"},"source":["Иногда известное нам слово встречается в редком для себя контексте (например, после слова, с которым оно не встречалось в обучающей выборке). Соответственно, языковая модель скорее всего присвоит нулевую вероятность такому событию. Чтобы такого не происходило, нужно уменьшить значения вероятности от некоторых более частотных событий и за счёт этого немного повысить вероятность более редких. Так и происходит сглаживание."],"id":"EOix1KMorscO"},{"cell_type":"code","execution_count":null,"metadata":{"id":"yc7aem1ka-MJ"},"outputs":[],"source":[],"id":"yc7aem1ka-MJ"}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":5}